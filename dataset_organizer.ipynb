{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534008ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm  # For progress bars\n",
    "import time\n",
    "\n",
    "# Paths\n",
    "coco_json = \"wcs_20220205_bboxes_with_classes.json\"\n",
    "cropped_dir = \"yolo_subset/cropped_animals\"\n",
    "output_dir = \"yolo_subset/resnet_dataset_corrected\"\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Starting Dataset Organization\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "print(f\"Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"COCO JSON: {coco_json}\")\n",
    "print(f\"Cropped images: {cropped_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Load COCO data\n",
    "print(\"\\n[1/4] Loading COCO annotations...\")\n",
    "start_time = time.time()\n",
    "with open(coco_json) as f:\n",
    "    coco_data = json.load(f)\n",
    "load_time = time.time() - start_time\n",
    "print(f\"✓ Loaded {len(coco_data['images'])} images and {len(coco_data['annotations'])} annotations in {load_time:.2f}s\")\n",
    "\n",
    "# Create mapping from original paths to image data\n",
    "print(\"\\n[2/4] Creating path mappings...\")\n",
    "path_to_data = {}\n",
    "path_conversions = 0\n",
    "\n",
    "for img in tqdm(coco_data[\"images\"], desc=\"Processing images\"):\n",
    "    original_path = img[\"file_name\"]\n",
    "    clean_path = original_path.replace(\"humans/\", \"animals/\")\n",
    "    if clean_path != original_path:\n",
    "        path_conversions += 1\n",
    "    path_to_data[clean_path] = img\n",
    "\n",
    "print(f\"  • Created {len(path_to_data)} path mappings\")\n",
    "print(f\"  • Performed {path_conversions} path conversions (humans→animals)\")\n",
    "\n",
    "category_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in coco_data[\"categories\"]}\n",
    "print(f\"\\n  • Found {len(category_id_to_name)} categories:\")\n",
    "for i, (cat_id, cat_name) in enumerate(list(category_id_to_name.items())[:5]):\n",
    "    print(f\"    {cat_id}: {cat_name}\" + (\"...\" if i == 4 else \"\"))\n",
    "\n",
    "# Create class folders\n",
    "print(\"\\n[3/4] Preparing directory structure...\")\n",
    "os.makedirs(f\"{output_dir}/train\", exist_ok=True)\n",
    "os.makedirs(f\"{output_dir}/val\", exist_ok=True)\n",
    "print(f\"✓ Created base directories at {output_dir}\")\n",
    "\n",
    "def get_original_path(crop_path):\n",
    "    \"\"\"Convert animals_0003_1406_crop0.jpg → animals/0003/1406.jpg\"\"\"\n",
    "    parts = crop_path.split('_')\n",
    "    if len(parts) >= 3 and parts[0] == \"animals\":\n",
    "        return f\"animals/{parts[1]}/{parts[2].split('.')[0]}.jpg\"\n",
    "    return None\n",
    "\n",
    "print(\"\\n[4/4] Organizing cropped images...\")\n",
    "total_stats = {\"train\": {\"matched\": 0, \"unmatched\": 0}, \"val\": {\"matched\": 0, \"unmatched\": 0}}\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"Processing {split} set\")\n",
    "    print(f\"{'='*30}\")\n",
    "    \n",
    "    split_files = [f for f in os.listdir(f\"{cropped_dir}/{split}\") if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    print(f\"Found {len(split_files)} images to process\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    stats = {\"matched\": 0, \"unmatched\": 0}\n",
    "    class_distribution = defaultdict(int)\n",
    "    \n",
    "    for crop_path in tqdm(split_files, desc=f\"Processing {split}\"):\n",
    "        # Find original path\n",
    "        original_path = get_original_path(crop_path)\n",
    "        img_data = path_to_data.get(original_path) if original_path else None\n",
    "        \n",
    "        if not img_data:\n",
    "            stats[\"unmatched\"] += 1\n",
    "            continue\n",
    "            \n",
    "        # Get classes\n",
    "        classes = set()\n",
    "        for ann in coco_data[\"annotations\"]:\n",
    "            if ann[\"image_id\"] == img_data[\"id\"]:\n",
    "                classes.add(category_id_to_name[ann[\"category_id\"]])\n",
    "        \n",
    "        if not classes:\n",
    "            stats[\"unmatched\"] += 1\n",
    "            continue\n",
    "            \n",
    "        class_name = list(classes)[0].replace(\" \", \"_\")\n",
    "        os.makedirs(f\"{output_dir}/{split}/{class_name}\", exist_ok=True)\n",
    "        \n",
    "        shutil.copy2(\n",
    "            f\"{cropped_dir}/{split}/{crop_path}\",\n",
    "            f\"{output_dir}/{split}/{class_name}/{crop_path}\"\n",
    "        )\n",
    "        stats[\"matched\"] += 1\n",
    "        class_distribution[class_name] += 1\n",
    "    \n",
    "    total_stats[split] = stats\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n{split.upper()} Results:\")\n",
    "    print(f\"- Processing time: {elapsed:.2f}s ({elapsed/max(1,len(split_files)):.3f}s per image)\")\n",
    "    print(f\"- Matched: {stats['matched']} ({stats['matched']/max(1,len(split_files))*100:.1f}%)\")\n",
    "    print(f\"- Unmatched: {stats['unmatched']}\")\n",
    "    \n",
    "    print(\"\\nClass distribution (top 5):\")\n",
    "    for cls, count in sorted(class_distribution.items(), key=lambda x: -x[1])[:5]:\n",
    "        print(f\"  {cls}: {count} images\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Organization Complete!\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "total_matched = total_stats[\"train\"][\"matched\"] + total_stats[\"val\"][\"matched\"]\n",
    "total_unmatched = total_stats[\"train\"][\"unmatched\"] + total_stats[\"val\"][\"unmatched\"]\n",
    "total_images = total_matched + total_unmatched\n",
    "\n",
    "print(\"Final Statistics:\")\n",
    "print(f\"- Total matched images: {total_matched} ({total_matched/max(1,total_images)*100:.1f}%)\")\n",
    "print(f\"- Total unmatched images: {total_unmatched}\")\n",
    "print(f\"- Output directory: {output_dir}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Verify the directory structure\")\n",
    "print(\"2. Check unmatched images if percentage is high\")\n",
    "print(\"3. Proceed with training using the organized dataset\")\n",
    "\n",
    "# Save stats to file\n",
    "with open(f\"{output_dir}/organization_stats.txt\", \"w\") as f:\n",
    "    f.write(\"Dataset Organization Report\\n\")\n",
    "    f.write(f\"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(f\"Total matched images: {total_matched}\\n\")\n",
    "    f.write(f\"Total unmatched images: {total_unmatched}\\n\\n\")\n",
    "    f.write(\"Details per split:\\n\")\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        f.write(f\"{split.upper()}: {total_stats[split]['matched']} matched, {total_stats[split]['unmatched']} unmatched\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
