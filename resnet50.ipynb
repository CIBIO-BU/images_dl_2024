{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3703915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Precision, Recall, AveragePrecision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = len(ImageFolder(\"cropped_animals/train\").classes)  # Auto-detect classes\n",
    "\n",
    "# Augmentations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Datasets (corrected paths)\n",
    "train_dataset = ImageFolder(\"cropped_animals/train\", transform=train_transform)\n",
    "val_dataset = ImageFolder(\"cropped_animals/val\", transform=val_transform)\n",
    "\n",
    "# Class weights for imbalance\n",
    "class_counts = torch.bincount(torch.tensor(train_dataset.targets))\n",
    "class_weights = (1. / class_counts.float()) * len(class_counts) / 2.0\n",
    "weights = class_weights[train_dataset.targets]\n",
    "sampler = torch.utils.data.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "# Metrics\n",
    "precision = Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro').cuda()\n",
    "recall = Recall(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro').cuda()\n",
    "map_metric = AveragePrecision(task=\"multiclass\", num_classes=NUM_CLASSES).cuda()\n",
    "\n",
    "def log_metrics(prefix, preds, targets):\n",
    "    print(f\"\\n{prefix} Metrics:\")\n",
    "    print(f\"• Precision: {precision(preds, targets):.4f}\")\n",
    "    print(f\"• Recall: {recall(preds, targets):.4f}\")\n",
    "    print(f\"• mAP: {map_metric(preds, targets):.4f}\")\n",
    "\n",
    "# Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, NUM_CLASSES)\n",
    ")\n",
    "model = model.cuda()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_preds, all_targets = [], []\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        all_preds.append(outputs.argmax(dim=1))\n",
    "        all_targets.append(labels)\n",
    "    \n",
    "    # Train metrics\n",
    "    train_preds = torch.cat(all_preds)\n",
    "    train_targets = torch.cat(all_targets)\n",
    "    log_metrics(\"Train\", train_preds, train_targets)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            val_preds.append(outputs.argmax(dim=1))\n",
    "            val_targets.append(labels)\n",
    "    \n",
    "    # Val metrics\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    log_metrics(\"Validation\", val_preds, val_targets)\n",
    "    \n",
    "    # LR scheduling\n",
    "    val_acc = (val_preds == val_targets).float().mean()\n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"• Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "    print(f\"• Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "    print(f\"• Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"• LR: {optimizer.param_groups[0]['lr']:.2e}\\n\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(val_targets.cpu(), val_preds.cpu())\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
    "plt.savefig(\"confusion_matrix.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
