{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3703915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# ===== Logging Setup =====\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f\"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ===== Configuration =====\n",
    "DATA_DIR = \"resnet_dataset_corrected\"\n",
    "MODEL_SAVE_PATH = \"resnet50_wildlife.pth\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 15\n",
    "LR = 0.001\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger.info(f\"\\n{'='*50}\")\n",
    "logger.info(\"ResNet50 Training Setup\")\n",
    "logger.info(f\"{'='*50}\")\n",
    "logger.info(f\"Device: {DEVICE}\")\n",
    "logger.info(f\"Batch size: {BATCH_SIZE}\")\n",
    "logger.info(f\"Epochs: {EPOCHS}\")\n",
    "logger.info(f\"Learning rate: {LR}\")\n",
    "logger.info(f\"Data directory: {DATA_DIR}\")\n",
    "\n",
    "# ===== Data Augmentation =====\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ===== Dataset Preparation =====\n",
    "logger.info(\"\\n[1/4] Loading datasets...\")\n",
    "train_dataset = ImageFolder(f\"{DATA_DIR}/train\", transform=train_transform)\n",
    "val_dataset = ImageFolder(f\"{DATA_DIR}/val\", transform=val_transform)\n",
    "\n",
    "# Class weights for imbalance\n",
    "class_counts = torch.bincount(torch.tensor(train_dataset.targets))\n",
    "class_weights = (1. / class_counts.float()) * len(class_counts) / 2.0\n",
    "weights = class_weights[train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(weights, len(train_dataset))\n",
    "\n",
    "logger.info(f\"Train samples: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation samples: {len(val_dataset)}\")\n",
    "logger.info(f\"Classes: {train_dataset.classes}\")\n",
    "\n",
    "# ===== Data Loaders =====\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "# ===== Model Setup =====\n",
    "logger.info(\"\\n[2/4] Initializing model...\")\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Modify final layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, len(train_dataset.classes))\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ===== Training Setup =====\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, verbose=True)\n",
    "\n",
    "# Metrics\n",
    "metrics = {\n",
    "    'accuracy': Accuracy(task='multiclass', num_classes=len(train_dataset.classes)).to(DEVICE),\n",
    "    'precision': Precision(task='multiclass', average='macro', num_classes=len(train_dataset.classes)).to(DEVICE),\n",
    "    'recall': Recall(task='multiclass', average='macro', num_classes=len(train_dataset.classes)).to(DEVICE),\n",
    "    'f1': F1Score(task='multiclass', average='macro', num_classes=len(train_dataset.classes)).to(DEVICE)\n",
    "}\n",
    "\n",
    "# ===== Training Loop =====\n",
    "logger.info(\"\\n[3/4] Starting training...\")\n",
    "best_val_acc = 0.0\n",
    "history = defaultdict(list)\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_outputs = []\n",
    "    val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_outputs.append(outputs)\n",
    "            val_targets.append(labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    \n",
    "    val_outputs = torch.cat(val_outputs)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    \n",
    "    val_acc = metrics['accuracy'](val_outputs, val_targets)\n",
    "    val_precision = metrics['precision'](val_outputs, val_targets)\n",
    "    val_recall = metrics['recall'](val_outputs, val_targets)\n",
    "    val_f1 = metrics['f1'](val_outputs, val_targets)\n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc.item())\n",
    "    history['val_precision'].append(val_precision.item())\n",
    "    history['val_recall'].append(val_recall.item())\n",
    "    history['val_f1'].append(val_f1.item())\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        logger.info(f\"✓ New best model saved with val_acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Epoch summary\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    logger.info(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    logger.info(f\"Time: {epoch_time:.1f}s | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    logger.info(f\"Val Accuracy: {val_acc:.4f} | Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1: {val_f1:.4f}\")\n",
    "    logger.info(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "# ===== Training Complete =====\n",
    "logger.info(\"\\n[4/4] Training complete!\")\n",
    "logger.info(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "logger.info(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# ===== Plotting =====\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_acc'], label='Accuracy')\n",
    "plt.plot(history['val_precision'], label='Precision')\n",
    "plt.plot(history['val_recall'], label='Recall')\n",
    "plt.plot(history['val_f1'], label='F1 Score')\n",
    "plt.title('Validation Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')\n",
    "logger.info(\"✓ Training metrics plot saved to training_metrics.png\")\n",
    "\n",
    "# ===== Final Report =====\n",
    "logger.info(\"\\nFinal Report:\")\n",
    "logger.info(f\"Total training time: {time.time() - start_time:.1f} seconds\")\n",
    "logger.info(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "logger.info(\"\\nClass distribution:\")\n",
    "for i, class_name in enumerate(train_dataset.classes):\n",
    "    logger.info(f\"{class_name}: {torch.sum(torch.tensor(train_dataset.targets) == i).item()} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
