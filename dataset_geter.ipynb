{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsutil -m cp -r \"gs://public-datasets-lila/wcs-unzipped/*\" ./wcs_dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3787fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 - <<EOF\n",
    "import ijson\n",
    "from collections import defaultdict\n",
    "\n",
    "# Count category occurrences from local file\n",
    "category_counts = defaultdict(int)\n",
    "with open(\"wcs_camera_traps.json\", \"rb\") as f:  # 'rb' mode for ijson\n",
    "    for ann in ijson.items(f, \"annotations.item\"):\n",
    "        category_counts[ann[\"category_id\"]] += 1\n",
    "        print(f\"{ann['category_name']}:{category_counts[ann['category_id']]}\")\n",
    "\n",
    "# Get top 20 categories\n",
    "top_20 = sorted(category_counts.items(), key=lambda x: -x[1])[:20]\n",
    "top_20_ids = [cat_id for cat_id, _ in top_20]\n",
    "\n",
    "print(\"Top 20 category IDs:\", top_20_ids)\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load annotation data\n",
    "with open(\"wcs_camera_traps.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Define target category IDs\n",
    "target_category_ids = {\n",
    "    2, 372, 71, 96, 111, 374, 3, 115, 10,\n",
    "    317, 90, 11, 8, 468, 24\n",
    "}\n",
    "\n",
    "# Step 1: Get image IDs that have at least one annotation with a target category ID\n",
    "target_image_ids = set()\n",
    "\n",
    "for ann in data[\"annotations\"]:\n",
    "    if ann[\"category_id\"] in target_category_ids:\n",
    "        target_image_ids.add(ann[\"image_id\"])\n",
    "\n",
    "# Step 2: Map image_id -> file name\n",
    "id_to_filename = {img[\"id\"]: img[\"file_name\"] for img in data[\"images\"]}\n",
    "\n",
    "# Step 3: Create list of full GCS paths\n",
    "output_paths = []\n",
    "for img_id in target_image_ids:\n",
    "    if img_id in id_to_filename:\n",
    "        file_path = id_to_filename[img_id]\n",
    "        gcs_path = f\"gs://public-datasets-lila/wcs-unzipped/animals/{file_path}\"\n",
    "        output_paths.append(gcs_path)\n",
    "\n",
    "# Step 4: Save to a file\n",
    "with open(\"target_animal_image_paths.txt\", \"w\") as f:\n",
    "    for path in output_paths:\n",
    "        f.write(path + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(output_paths)} image paths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "INPUT_FILE = \"target_animal_image_paths.txt\"\n",
    "OUTPUT_DIR = \"downloaded_images\"\n",
    "MAX_WORKERS = 10  # Threads, adjust depending on bandwidth/CPU\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def download_image(line):\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        return None\n",
    "\n",
    "    rel_path = line.replace(\"gs://public-datasets-lila/wcs-unzipped/\", \"\")\n",
    "    safe_name = rel_path.replace(\"/\", \"_\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, safe_name)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        return f\"‚úî Skipped: {safe_name}\"\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"gsutil\", \"cp\", line, output_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        if result.returncode == 0:\n",
    "            return f\"‚úÖ Downloaded: {safe_name}\"\n",
    "        else:\n",
    "            return f\"‚ùå Failed: {safe_name} ‚Äî {result.stderr.decode().strip()}\"\n",
    "    except Exception as e:\n",
    "        return f\"üí• Error: {safe_name} ‚Äî {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    with open(INPUT_FILE, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [executor.submit(download_image, line) for line in lines]\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Paths ===\n",
    "coco_json_path = \"wcs_camera_traps.json\"          \n",
    "download_dir = \"downloaded_images\"           \n",
    "output_dir = \"organized_by_species\"          \n",
    "\n",
    "# === Load JSON ===\n",
    "with open(coco_json_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === Map categories and images ===\n",
    "category_id_to_name = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
    "image_id_to_file = {\n",
    "    img[\"id\"]: img[\"file_name\"].replace(\"/\", \"_\")\n",
    "    for img in data[\"images\"]\n",
    "}\n",
    "\n",
    "# === Map file_name to species ===\n",
    "file_to_species = defaultdict(list)\n",
    "\n",
    "for ann in data[\"annotations\"]:\n",
    "    img_id = ann[\"image_id\"]\n",
    "    cat_id = ann[\"category_id\"]\n",
    "    file_name = image_id_to_file.get(img_id)\n",
    "    species = category_id_to_name.get(cat_id)\n",
    "    if file_name and species:\n",
    "        file_to_species[file_name].append(species)\n",
    "\n",
    "# === Organize files ===\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file_name, species_list in file_to_species.items():\n",
    "    src_path = os.path.join(download_dir, file_name)\n",
    "    if not os.path.exists(src_path):\n",
    "        print(f\"‚ö†Ô∏è Skipping {file_name} (not found)\")\n",
    "        continue\n",
    "\n",
    "    for species in set(species_list):  # avoid duplicates\n",
    "        species_dir = os.path.join(output_dir, species)\n",
    "        os.makedirs(species_dir, exist_ok=True)\n",
    "        dst_path = os.path.join(species_dir, file_name)\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "        print(f\"üì¶ Copied {file_name} to {species_dir}\")\n",
    "\n",
    "print(\"‚úÖ Done organizing by species!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
