{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce62f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55746e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo detect train \\\n",
    "    data=data.yaml \\\n",
    "    model=yolov8n.pt \\\n",
    "    epochs=100 \\\n",
    "    imgsz=640 \\\n",
    "    batch=8 \\\n",
    "    workers=2 \\\n",
    "    device=0 \\\n",
    "    cache=ram \\\n",
    "    exist_ok=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ea798",
   "metadata": {},
   "source": [
    "## box_loss: 0.945 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e937db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup yolo detect train \\\n",
    "    data=data.yaml \\\n",
    "    model=yolov8s.pt \\\n",
    "    epochs=100 \\\n",
    "    imgsz=0 \\\n",
    "    batch=8 \\              \n",
    "    workers=2 \\            \n",
    "    device=0 \\\n",
    "    lr0=0.01 \\\n",
    "    patience=10 \\\n",
    "    cache=False \\          \n",
    "    augment=True \\\n",
    "    verbose=True > train_repaired.log 2>&1 &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3951b82",
   "metadata": {},
   "source": [
    "## box_loss: 0.8774\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nohup yolo detect train \\\n",
    "    resume=True \\\n",
    "    model=runs/detect/train4/weights/last.pt \\\n",
    "    data=data.yaml \\\n",
    "    epochs=100 \\\n",
    "    imgsz=640 \\\n",
    "    batch=4 \\             \n",
    "    workers=1 \\            \n",
    "    device=0 \\\n",
    "    lr0=0.01 \\\n",
    "    patience=10 \\\n",
    "    cache=False \\          \n",
    "    augment=False \\        \n",
    "    val=False \\           \n",
    "    verbose=True > train_light.log 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo train \\\n",
    "  model=yolov11l.pt \\\n",
    "  data=data.yaml \\  \n",
    "  epochs=100 \\\n",
    "  imgsz=480 \\\n",
    "  batch=16 \\\n",
    "  workers=2 \\            \n",
    "  device=0 \\\n",
    "  lr0=0.005 \\\n",
    "  patience=10 \\\n",
    "  cache=False \\          \n",
    "  augment=False \\        \n",
    "  val=False \\ \n",
    "  project=yolov11_subset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo val model=yolov11_subset_results/lr001/weights/best.pt data=data.yaml conf=0.1 iou=0.5 plots=True workers=0 cache=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo train model=yolo11l data=data.yaml epochs=100 imgsz=640 batch=8 workers=0 device=0 lr0=0.005 augment=True optimizer=\"AdamW\" cls=0.5 pretrained=True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time \n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Config\n",
    "data_yaml = 'data.yaml'  # Your dataset config\n",
    "batch_size = 2\n",
    "image_size = 512\n",
    "epochs = 20\n",
    "\n",
    "# Dataset\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, yaml_path, mode='train'):\n",
    "        with open(yaml_path) as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        \n",
    "        self.img_dir = os.path.join(data['path'], data[mode])\n",
    "        self.label_dir = self.img_dir.replace('images', 'labels')\n",
    "        self.images = [f for f in os.listdir(self.img_dir) \n",
    "                      if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        self.classes = data['names']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = torchvision.transforms.functional.to_tensor(img)\n",
    "        img = torchvision.transforms.functional.resize(img, [image_size]*2)\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = os.path.join(self.label_dir, \n",
    "                                os.path.splitext(self.images[idx])[0] + '.txt')\n",
    "        boxes, labels = [], []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path) as f:\n",
    "                for line in f:\n",
    "                    class_id, xc, yc, w, h = map(float, line.strip().split())\n",
    "                    # Convert YOLO to Pascal VOC\n",
    "                    x1 = (xc - w/2) * image_size\n",
    "                    y1 = (yc - h/2) * image_size\n",
    "                    x2 = (xc + w/2) * image_size\n",
    "                    y2 = (yc + h/2) * image_size\n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "                    labels.append(int(class_id) + 1)  # +1 because background is class 0\n",
    "        \n",
    "        target = {\n",
    "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': (torch.tensor(boxes)[:, 3] - torch.tensor(boxes)[:, 1]) * \n",
    "                    (torch.tensor(boxes)[:, 2] - torch.tensor(boxes)[:, 0]),\n",
    "            'iscrowd': torch.zeros(len(labels), dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "# Model\n",
    "def create_model(num_classes):\n",
    "    backbone = torchvision.models.mobilenet_v2(weights='DEFAULT').features\n",
    "    backbone.out_channels = 1280  # MobilenetV2 feature dimension\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((32, 64, 128, 256),),\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)\n",
    "    )\n",
    "    \n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "        featmap_names=['0'],\n",
    "        output_size=7,\n",
    "        sampling_ratio=2\n",
    "    )\n",
    "    \n",
    "    return FasterRCNN(\n",
    "        backbone,\n",
    "        num_classes=num_classes,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler\n",
    "    )\n",
    "\n",
    "# Training\n",
    "def train():\n",
    "    # Data\n",
    "    train_set = YOLODataset(data_yaml, 'train')\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: tuple(zip(*x))\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    model = create_model(len(train_set.classes) + 1).to('cuda')\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(f\"\\nðŸš€ Starting training on {len(train_set)} images\")\n",
    "    print(f\"ðŸ“¦ Batch size: {batch_size} | ðŸ”„ Total batches: {len(train_loader)}\")\n",
    "    print(f\"ðŸ”¥ Epochs: {epochs} | ðŸ’» Device: {next(model.parameters()).device}\\n\")\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "            batch_start = time.time()\n",
    "\n",
    "            # Move to GPU\n",
    "            images = [img.to('cuda') for img in images]\n",
    "            targets = [{k: v.to('cuda') for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            # Forward + backward\n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_time = time.time() - batch_start\n",
    "            epoch_loss += losses.item()\n",
    "            avg_loss = epoch_loss / (batch_idx + 1)\n",
    "\n",
    "            print(\n",
    "                f\"\\rEpoch {epoch+1}/{epochs} | \"\n",
    "                f\"Batch {batch_idx+1}/{len(train_loader)} | \"\n",
    "                f\"Loss: {losses.item():.3f} (avg: {avg_loss:.3f}) | \"\n",
    "                f\"Time: {batch_time:.2f}s/batch | \"\n",
    "                f\"Mem: {torch.cuda.memory_allocated()/1e9:.2f}GB\",\n",
    "                end=\"\", flush=True\n",
    "            )                    \n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"\\nâœ… Epoch {epoch+1} complete | \"\n",
    "              f\"Avg loss: {epoch_loss/len(train_loader):.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s | \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.2e}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
